import OpenAI from 'openai';

// å®šä¹‰æ¶ˆæ¯ç±»å‹
export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

// å®šä¹‰èŠå¤©è¯·æ±‚ç±»å‹
export interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  stream?: boolean;
}

// å®šä¹‰èŠå¤©å“åº”ç±»å‹
export interface ChatResponse {
  message: ChatMessage;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

// é…ç½®é€‰é¡¹
export interface ChatServiceOptions {
  apiKey: string;
  baseURL?: string;
  model?: string;
  systemMessage?: string;
}

// é»˜è®¤é…ç½®
const DEFAULT_OPTIONS: Partial<ChatServiceOptions> = {
  baseURL: 'https://api.deepseek.com',
  model: 'deepseek-chat',
  systemMessage: 'ç”¨æˆ·ä¼šå‘ä½ æé—®ï¼Œä½ åªéœ€è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦è¿›è¡Œä»»ä½•è§£é‡Šã€‚',
};

/**
 * èŠå¤©æœåŠ¡ç±»ï¼Œç”¨äºä¸ DeepSeek API äº¤äº’
 */
export class ChatService {
  private client: OpenAI;
  private defaultModel: string;
  private systemMessage: string;

  constructor(options: ChatServiceOptions) {
    const mergedOptions = { ...DEFAULT_OPTIONS, ...options };

    this.client = new OpenAI({
      baseURL: mergedOptions.baseURL,
      apiKey: mergedOptions.apiKey,
      dangerouslyAllowBrowser: true,
    });

    this.defaultModel = mergedOptions.model || 'deepseek-chat';
    this.systemMessage = mergedOptions.systemMessage || 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚';
  }

  /**
   * è·å–å¸¦æœ‰ç³»ç»Ÿæ¶ˆæ¯çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
   * @param messages ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
   * @returns åŒ…å«ç³»ç»Ÿæ¶ˆæ¯çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
   */
  getMessagesWithSystem(messages: ChatMessage[]): ChatMessage[] {
    // æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«ç³»ç»Ÿæ¶ˆæ¯
    const hasSystemMessage = messages.some(msg => msg.role === 'system');

    if (hasSystemMessage) {
      return messages;
    }

    // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    return [{ role: 'system', content: this.systemMessage }, ...messages];
  }

  /**
   * ä½¿ç”¨æµå¼å“åº”å‘é€èŠå¤©è¯·æ±‚
   * @param request èŠå¤©è¯·æ±‚å‚æ•°
   * @param onMessage æ¥æ”¶æ¶ˆæ¯çš„å›è°ƒå‡½æ•°
   * @param onComplete å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
   * @param onError é”™è¯¯å¤„ç†å›è°ƒå‡½æ•°
   */
  async sendStreamMessage(
    request: ChatRequest,
    onMessage: (content: string) => void,
    onComplete?: (response: ChatResponse) => void,
    onError?: (error: Error) => void
  ): Promise<void> {
    try {
      // ç¡®ä¿ä½¿ç”¨æµå¼è¾“å‡º
      const streamRequest = { ...request, stream: true };

      // ç¡®ä¿åŒ…å«ç³»ç»Ÿæ¶ˆæ¯
      const messagesWithSystem = this.getMessagesWithSystem(streamRequest.messages);

      const stream = await this.client.chat.completions.create({
        messages: messagesWithSystem,
        model: streamRequest.model || this.defaultModel,
        temperature: streamRequest.temperature,
        stream: true,
      });

      let fullContent = '';

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        console.log('ğŸš€ ~ ChatService ~ forawait ~ content:', content);
        if (content) {
          fullContent += content;
          onMessage(content);
        }
      }

      if (onComplete) {
        onComplete({
          message: {
            role: 'assistant',
            content: fullContent,
          },
        });
      }
    } catch (error) {
      console.error('æµå¼èŠå¤©è¯·æ±‚å¤±è´¥:', error);
      if (onError) {
        onError(error);
      } else {
        throw error;
      }
    }
  }
}
